"""
è®­ç»ƒå™¨åŸºç±»
"""
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from typing import Dict, Any, Optional
import time
import os
from pathlib import Path
from abc import ABC, abstractmethod

from utils.checkpoint import CheckpointManager
from utils.metrics import MetricsTracker
from utils.visualization import TrainingVisualizer
from training.callbacks import CallbackList


class TrainerBase(ABC):
    """è®­ç»ƒå™¨åŸºç±»"""

    def __init__(
        self,
        model: nn.Module,
        train_loader: DataLoader,
        val_loader: DataLoader,
        optimizer: torch.optim.Optimizer,
        scheduler: Any,
        device: str = 'cuda',
        experiment_dir: str = 'experiments/runs',
        use_amp: bool = False
    ):
        """
        Args:
            model: æ¨¡å‹
            train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
            val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
            optimizer: ä¼˜åŒ–å™¨
            scheduler: å­¦ä¹ ç‡è°ƒåº¦å™¨
            device: è®­ç»ƒè®¾å¤‡
            experiment_dir: å®éªŒä¿å­˜ç›®å½•
            use_amp: æ˜¯å¦ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
        """
        self.model = model.to(device)
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.optimizer = optimizer
        self.scheduler = scheduler
        self.device = device
        self.use_amp = use_amp

        # å®éªŒç›®å½•
        self.experiment_dir = Path(experiment_dir)
        self.experiment_dir.mkdir(parents=True, exist_ok=True)

        # æ··åˆç²¾åº¦è®­ç»ƒ
        if use_amp:
            self.scaler = torch.cuda.amp.GradScaler()

        # å·¥å…·
        self.checkpoint_manager = CheckpointManager(
            checkpoint_dir=str(self.experiment_dir / 'checkpoints')
        )
        self.metrics_tracker = MetricsTracker()
        self.visualizer = TrainingVisualizer()

        # Callbacks
        self.callbacks = CallbackList()

        # è®­ç»ƒçŠ¶æ€
        self.current_epoch = 0
        self.global_step = 0

    def add_callback(self, callback):
        """æ·»åŠ callback"""
        self.callbacks.add(callback)

    def setup_callbacks(
        self,
        early_stopping_config: Optional[Dict] = None,
        checkpoint_config: Optional[Dict] = None
    ):
        """
        è®¾ç½®callbacks

        Args:
            early_stopping_config: æ—©åœé…ç½®
            checkpoint_config: checkpointé…ç½®
        """
        from training.callbacks import EarlyStopping, ModelCheckpoint

        print("\né…ç½®Callbacks:")

        # æ—©åœé…ç½®
        if early_stopping_config and early_stopping_config.get('enable', False):
            monitor = early_stopping_config.get('monitor', 'val_loss')
            mode = early_stopping_config.get('mode', 'min')

            early_stopping = EarlyStopping(
                patience=early_stopping_config.get('patience', 10),
                monitor=monitor,
                mode=mode,
                restore_best_weights=early_stopping_config.get('restore_best_weights', True)
            )
            self.add_callback(early_stopping)
            print(f"  âœ… EarlyStopping:")
            print(f"     - monitor: {monitor}")
            print(f"     - mode: {mode}")
            print(f"     - patience: {early_stopping.patience}")

        # Checkpointé…ç½®
        if checkpoint_config and checkpoint_config.get('save_best', True):
            monitor_metric = checkpoint_config.get('monitor_metric', 'val_acc')
            monitor_mode = checkpoint_config.get('monitor_mode', 'max')

            model_checkpoint = ModelCheckpoint(
                save_dir=self.checkpoint_manager.checkpoint_dir,
                monitor=monitor_metric,
                mode=monitor_mode,
                save_frequency=checkpoint_config.get('save_frequency', 5),
                keep_last_n=checkpoint_config.get('keep_last_n', 3)
            )
            self.add_callback(model_checkpoint)
            print(f"  âœ… ModelCheckpoint:")
            print(f"     - monitor: {monitor_metric}")
            print(f"     - mode: {monitor_mode}")
            print(f"     - save_frequency: {checkpoint_config.get('save_frequency', 5)}")
            print(f"     - keep_last_n: {checkpoint_config.get('keep_last_n', 3)}")

    @abstractmethod
    def train_epoch(self) -> Dict[str, float]:
        """
        è®­ç»ƒä¸€ä¸ªepoch

        Returns:
            metrics: è®­ç»ƒæŒ‡æ ‡å­—å…¸
        """
        pass

    @abstractmethod
    def validate_epoch(self) -> Dict[str, float]:
        """
        éªŒè¯ä¸€ä¸ªepoch

        Returns:
            metrics: éªŒè¯æŒ‡æ ‡å­—å…¸
        """
        pass

    def update_epoch(self, epoch: int, total_epochs: int):
        """
        ğŸ”§ æ–°å¢æ–¹æ³•: æ›´æ–°epochç›¸å…³çš„é…ç½®

        å­ç±»å¯ä»¥é‡å†™æ­¤æ–¹æ³•ä»¥å®ç°:
        1. æ¸è¿›å¼å¢å¼º - æ›´æ–°æ•°æ®å¢å¼ºå¼ºåº¦
        2. æ¸è¿›å¼æŸå¤± - æ›´æ–°æŸå¤±å‡½æ•°æƒé‡
        3. å…¶ä»–éœ€è¦æ ¹æ®è®­ç»ƒè¿›åº¦è°ƒæ•´çš„é…ç½®

        Args:
            epoch: å½“å‰epoch
            total_epochs: æ€»epochæ•°
        """
        # é»˜è®¤å®ç°:ä»€ä¹ˆéƒ½ä¸åš
        # å­ç±»å¯ä»¥é‡å†™æ­¤æ–¹æ³•
        pass

    def train(
        self,
        epochs: int,
        log_interval: int = 10,
        save_config: Optional[Dict] = None
    ):
        """
        å®Œæ•´è®­ç»ƒæµç¨‹

        ä¿®å¤å†…å®¹:
        1. åœ¨æ¯ä¸ªepochå¼€å§‹å‰è°ƒç”¨update_epochæ–¹æ³•

        Args:
            epochs: è®­ç»ƒè½®æ•°
            log_interval: æ—¥å¿—æ‰“å°é—´éš”
            save_config: ä¿å­˜é…ç½®
        """
        print("=" * 80)
        print(f"å¼€å§‹è®­ç»ƒ: {epochs} epochs")
        print("=" * 80)

        # ä¿å­˜é…ç½®
        if save_config:
            self._save_config(save_config)

        # è®­ç»ƒå¾ªç¯
        for epoch in range(epochs):
            self.current_epoch = epoch
            epoch_start_time = time.time()

            # ğŸ”§ ä¿®å¤: åœ¨æ¯ä¸ªepochå¼€å§‹å‰è°ƒç”¨update_epoch
            self.update_epoch(epoch, epochs)

            # è®­ç»ƒä¸€ä¸ªepoch
            train_metrics = self.train_epoch()

            # éªŒè¯ä¸€ä¸ªepoch
            val_metrics = self.validate_epoch()

            # æ›´æ–°å­¦ä¹ ç‡
            self._update_lr(val_metrics)

            # è®°å½•å­¦ä¹ ç‡
            lr = self.optimizer.param_groups[0]['lr']

            # è®°å½•æŒ‡æ ‡
            epoch_metrics = {
                **train_metrics,
                **val_metrics,
                'learning_rate': lr
            }
            self.metrics_tracker.update(epoch_metrics)

            # å›è°ƒ
            callback_metrics = {
                'epoch': epoch,
                'train_loss': train_metrics.get('train_loss', 0),
                'val_loss': val_metrics.get('val_loss', 0),
                'val_acc': val_metrics.get('val_acc', 0)
            }
            self.callbacks.on_epoch_end(epoch, callback_metrics, self.model, self.optimizer)

            # æ‰“å°æ—¥å¿—
            epoch_time = time.time() - epoch_start_time
            self._print_epoch_log(epoch, epochs, train_metrics, val_metrics, epoch_time)

            # æ£€æŸ¥æ—©åœ
            if self.callbacks.should_stop():
                print(f"\næ—©åœè§¦å‘,åœ¨ç¬¬ {epoch + 1} è½®åœæ­¢è®­ç»ƒ")
                break

        # è®­ç»ƒç»“æŸ
        print("\n" + "=" * 80)
        print("è®­ç»ƒå®Œæˆ!")
        print("=" * 80)

        # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
        self._plot_training_curves()

        # åŠ è½½æœ€ä½³æ¨¡å‹
        self._load_best_model()

    def _update_lr(self, val_metrics: Dict[str, float]):
        """æ›´æ–°å­¦ä¹ ç‡"""
        if self.scheduler is not None:
            # ReduceLROnPlateauéœ€è¦ä¼ å…¥metric
            if isinstance(self.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):
                self.scheduler.step(val_metrics.get('val_acc', 0))
            # CombinedSchedulerä¹Ÿéœ€è¦ä¼ å…¥metric
            elif hasattr(self.scheduler, 'step') and 'metric' in self.scheduler.step.__code__.co_varnames:
                self.scheduler.step(metric=val_metrics.get('val_acc', 0))
            else:
                self.scheduler.step()

    def _print_epoch_log(
        self,
        epoch: int,
        total_epochs: int,
        train_metrics: Dict[str, float],
        val_metrics: Dict[str, float],
        epoch_time: float
    ):
        """æ‰“å°epochæ—¥å¿—"""
        lr = self.optimizer.param_groups[0]['lr']

        log_str = f"Epoch [{epoch + 1:3d}/{total_epochs}] | "
        log_str += f"Time: {epoch_time:.2f}s | "
        log_str += f"LR: {lr:.6f} | "

        # è®­ç»ƒæŒ‡æ ‡
        for key, value in train_metrics.items():
            log_str += f"{key}: {value:.4f} | "

        # éªŒè¯æŒ‡æ ‡
        for key, value in val_metrics.items():
            log_str += f"{key}: {value:.4f} | "

        print(log_str.rstrip(" | "))

    def _plot_training_curves(self):
        """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
        history = self.metrics_tracker.get_history()

        if 'train_loss' in history and 'val_loss' in history:
            self.visualizer.plot_loss_curves(
                history['train_loss'],
                history['val_loss'],
                save_path=self.experiment_dir / 'visualizations' / 'loss_curve.png'
            )

        if 'train_acc' in history and 'val_acc' in history:
            self.visualizer.plot_accuracy_curves(
                history['train_acc'],
                history['val_acc'],
                save_path=self.experiment_dir / 'visualizations' / 'acc_curve.png'
            )

    def _load_best_model(self):
        """åŠ è½½æœ€ä½³æ¨¡å‹"""
        best_checkpoint = self.checkpoint_manager.get_best_checkpoint()
        if best_checkpoint is not None and os.path.exists(best_checkpoint):
            print(f"\nåŠ è½½æœ€ä½³æ¨¡å‹: {best_checkpoint}")
            checkpoint = torch.load(best_checkpoint, map_location=self.device)
            self.model.load_state_dict(checkpoint['model_state_dict'])

    def _save_config(self, config: Dict):
        """ä¿å­˜é…ç½®"""
        import yaml
        config_path = self.experiment_dir / 'config.yaml'
        with open(config_path, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, default_flow_style=False, allow_unicode=True)

    def save_checkpoint(self, filepath: str, **extra_state):
        """
        ä¿å­˜checkpoint

        Args:
            filepath: ä¿å­˜è·¯å¾„
            **extra_state: é¢å¤–çš„çŠ¶æ€
        """
        checkpoint = {
            'epoch': self.current_epoch,
            'global_step': self.global_step,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            **extra_state
        }

        if self.scheduler is not None:
            checkpoint['scheduler_state_dict'] = self.scheduler.state_dict()

        torch.save(checkpoint, filepath)

    def load_checkpoint(self, filepath: str):
        """
        åŠ è½½checkpoint

        Args:
            filepath: checkpointè·¯å¾„
        """
        checkpoint = torch.load(filepath, map_location=self.device)

        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])

        if 'scheduler_state_dict' in checkpoint and self.scheduler is not None:
            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])

        self.current_epoch = checkpoint.get('epoch', 0)
        self.global_step = checkpoint.get('global_step', 0)

        return checkpoint

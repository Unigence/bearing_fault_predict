"""
æœ‰ç›‘ç£è®­ç»ƒå™¨
"""
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from typing import Dict, Any, Tuple, Optional
from tqdm import tqdm
from pathlib import Path
import time
import os
import sys
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.manifold import TSNE
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from training.trainer_base import TrainerBase
from losses import CombinedLoss, ProgressiveCombinedLoss, compute_class_weights
from augmentation.mixup import MultiModalMixup, ManifoldMixup
from utils.visualization import TrainingVisualizer
from training.callbacks import EarlyStopping, ModelCheckpoint

class SupervisedTrainer(TrainerBase):
    """æœ‰ç›‘ç£è®­ç»ƒå™¨"""

    def __init__(
        self,
        model: nn.Module,
        train_loader: DataLoader,
        val_loader: DataLoader,
        optimizer: torch.optim.Optimizer,
        scheduler: Any,
        loss_config: Dict[str, Any],
        device: str = 'cuda',
        experiment_dir: str = 'experiments/runs',
        use_amp: bool = False,
        mixup_config: Optional[Dict[str, Any]] = None,
        gradient_clip_max_norm: float = 1.0
    ):
        """
        Args:
            model: æ¨¡å‹
            train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
            val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
            optimizer: ä¼˜åŒ–å™¨
            scheduler: å­¦ä¹ ç‡è°ƒåº¦å™¨
            loss_config: æŸå¤±å‡½æ•°é…ç½®
            device: è®­ç»ƒè®¾å¤‡
            experiment_dir: å®éªŒä¿å­˜ç›®å½•
            use_amp: æ˜¯å¦ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
            mixup_config: Mixupé…ç½®å­—å…¸
            gradient_clip_max_norm: æ¢¯åº¦è£å‰ªçš„æœ€å¤§èŒƒæ•°
        """
        super().__init__(
            model, train_loader, val_loader, optimizer, scheduler,
            device, experiment_dir, use_amp
        )

        self.gradient_clip_max_norm = gradient_clip_max_norm

        # åˆ›å»ºæŸå¤±å‡½æ•°
        self.criterion = self._create_criterion(loss_config)

        # åˆ›å»ºMixupç®¡ç†å™¨
        self.mixup_manager = None
        if mixup_config:
            self.mixup_manager = MultiModalMixup(
                time_domain_config=mixup_config.get('time_domain'),
                frequency_domain_config=mixup_config.get('frequency_domain'),
                feature_level_config=mixup_config.get('feature_level')
            )

        print(f"SupervisedTraineråˆå§‹åŒ–å®Œæˆ")
        if self.mixup_manager:
            print(f"  - æ—¶åŸŸMixup: {self.mixup_manager.time_domain_enabled}")
            print(f"  - é¢‘åŸŸMixup: {self.mixup_manager.frequency_domain_enabled}")
            print(f"  - ç‰¹å¾å±‚Mixup: {self.mixup_manager.feature_level_enabled}")
            print(f"  âš ï¸  æ³¨æ„: ä½¿ç”¨è¾“å…¥å±‚Mixupæ—¶å°†ç¦ç”¨ArcFaceæŸå¤±(ä»…ä½¿ç”¨Softmax)")
        else:
            print(f"  - Mixup: æœªå¯ç”¨")
        print(f"  - æ¢¯åº¦è£å‰ª: {gradient_clip_max_norm}")

    def _create_criterion(self, loss_config: Dict[str, Any]):
        """åˆ›å»ºæŸå¤±å‡½æ•°"""
        if loss_config.get('use_progressive', False):
            # æ¸è¿›å¼ç»„åˆæŸå¤±
            criterion = ProgressiveCombinedLoss(
                focal_alpha=loss_config['focal'].get('alpha', None),
                focal_gamma_init=loss_config['focal'].get('gamma_init', None),
                focal_gamma_min=loss_config['focal'].get('gamma_min', None),
                arcface_weight_init=loss_config['arcface'].get('weight_init', None),
                arcface_weight_max=loss_config['arcface'].get('weight_max', None),
                label_smoothing=loss_config.get('label_smoothing', 0.0)
            )
        else:
            # å›ºå®šæƒé‡ç»„åˆæŸå¤±
            criterion = CombinedLoss(
                focal_alpha=loss_config['focal'].get('alpha', None),
                focal_gamma=loss_config['focal'].get('gamma_init', None),
                focal_weight=loss_config['focal'].get('weight', None),
                arcface_weight=loss_config['arcface'].get('weight_init', 0.5),
                label_smoothing=loss_config.get('label_smoothing', 0.0)
            )

        return criterion

    def _move_batch_to_device(self, batch: Dict) -> Dict:
        """
        å°†batchæ•°æ®ç§»åˆ°è®¾å¤‡ä¸Š

        Args:
            batch: æ‰¹æ¬¡æ•°æ®å­—å…¸

        Returns:
            ç§»åˆ°è®¾å¤‡åçš„batch
        """
        device_batch = {}

        for key, value in batch.items():
            if isinstance(value, torch.Tensor):
                device_batch[key] = value.to(self.device)
            elif isinstance(value, dict):
                # é€’å½’å¤„ç†åµŒå¥—å­—å…¸ï¼ˆå¦‚å¯¹æ¯”å­¦ä¹ çš„view1/view2ï¼‰
                device_batch[key] = {}
                for sub_key, sub_value in value.items():
                    if isinstance(sub_value, torch.Tensor):
                        device_batch[key][sub_key] = sub_value.to(self.device)
                    else:
                        device_batch[key][sub_key] = sub_value
            else:
                device_batch[key] = value

        return device_batch

    def train_epoch(self) -> Dict[str, float]:
        """
        è®­ç»ƒä¸€ä¸ªepoch

        Returns:
            metrics: è®­ç»ƒæŒ‡æ ‡å­—å…¸ {'train_loss': ..., 'train_acc': ...}
        """
        self.model.train()

        total_loss = 0.0
        total_correct = 0
        total_samples = 0

        pbar = tqdm(self.train_loader, desc=f"Training Epoch {self.current_epoch+1}")

        for batch_idx, batch in enumerate(pbar):
            # ã€å…³é”®ä¿®å¤ã€‘ï¼šå…ˆå°†æ•´ä¸ªbatchç§»åˆ°è®¾å¤‡
            batch = self._move_batch_to_device(batch)

            # åº”ç”¨è¾“å…¥å±‚mixupï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.mixup_manager:
                # æ³¨æ„ï¼šç°åœ¨batchå·²ç»åœ¨è®¾å¤‡ä¸Šï¼Œæ‰€ä»¥ä¸éœ€è¦åœ¨apply_input_mixupä¸­å†æ¬¡ç§»åŠ¨
                mixed_batch, labels_a, labels_b, lam = self.mixup_manager.apply_input_mixup(
                    batch, self.device
                )
                use_mixup = labels_b is not None
            else:
                mixed_batch = batch
                labels_a = batch['label']  # å·²ç»åœ¨è®¾å¤‡ä¸Š
                labels_b = None
                lam = 1.0
                use_mixup = False

            # å‰å‘ä¼ æ’­ - æ ¹æ®æ˜¯å¦ä½¿ç”¨Mixupå†³å®šè®¡ç®—æ–¹å¼
            if self.use_amp:
                with torch.cuda.amp.autocast():
                    softmax_logits, arcface_logits, features = self.model(
                        mixed_batch, mode='supervised'
                    )

                    # Mixupæ—¶åªä½¿ç”¨SoftmaxæŸå¤±,ä¸ä½¿ç”¨ArcFace
                    if use_mixup:
                        loss_a = F.cross_entropy(softmax_logits, labels_a, reduction='mean')
                        loss_b = F.cross_entropy(softmax_logits, labels_b, reduction='mean')
                        loss = lam * loss_a + (1 - lam) * loss_b
                    else:
                        loss, loss_dict = self.criterion(softmax_logits, arcface_logits, labels_a)
            else:
                softmax_logits, arcface_logits, features = self.model(
                    mixed_batch, mode='supervised'
                )

                if use_mixup:
                    loss_a = F.cross_entropy(softmax_logits, labels_a, reduction='mean')
                    loss_b = F.cross_entropy(softmax_logits, labels_b, reduction='mean')
                    loss = lam * loss_a + (1 - lam) * loss_b
                else:
                    loss, loss_dict = self.criterion(softmax_logits, arcface_logits, labels_a)

            # åå‘ä¼ æ’­å’Œä¼˜åŒ–
            self.optimizer.zero_grad()

            if self.use_amp:
                self.scaler.scale(loss).backward()
                if self.gradient_clip_max_norm > 0:
                    self.scaler.unscale_(self.optimizer)
                    torch.nn.utils.clip_grad_norm_(
                        self.model.parameters(),
                        self.gradient_clip_max_norm
                    )
                self.scaler.step(self.optimizer)
                self.scaler.update()
            else:
                loss.backward()
                if self.gradient_clip_max_norm > 0:
                    torch.nn.utils.clip_grad_norm_(
                        self.model.parameters(),
                        self.gradient_clip_max_norm
                    )
                self.optimizer.step()

            # ç»Ÿè®¡å‡†ç¡®ç‡ - ä½¿ç”¨softmax_logits
            predictions = torch.argmax(softmax_logits, dim=1)
            if use_mixup:
                # Mixupæƒ…å†µä¸‹ï¼Œä½¿ç”¨ä¸»è¦æ ‡ç­¾è®¡ç®—å‡†ç¡®ç‡
                correct = (predictions == labels_a).sum().item()
            else:
                correct = (predictions == labels_a).sum().item()

            total_correct += correct
            total_samples += labels_a.size(0)
            total_loss += loss.item()

            # æ›´æ–°è¿›åº¦æ¡
            pbar.set_postfix({
                'loss': loss.item(),
                'acc': total_correct / total_samples
            })

        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        avg_loss = total_loss / len(self.train_loader)
        avg_acc = total_correct / total_samples

        return {
            'train_loss': avg_loss,
            'train_acc': avg_acc
        }

    def validate_epoch(self) -> Dict[str, float]:
        """
        éªŒè¯ä¸€ä¸ªepoch

        Returns:
            metrics: éªŒè¯æŒ‡æ ‡å­—å…¸ {'val_loss': ..., 'val_acc': ...}
        """
        self.model.eval()

        total_loss = 0.0
        total_correct = 0
        total_samples = 0

        pbar = tqdm(self.val_loader, desc=f"Validation Epoch {self.current_epoch+1}")

        with torch.no_grad():
            for batch in pbar:
                # ã€å…³é”®ä¿®å¤ã€‘ï¼šå°†batchç§»åˆ°è®¾å¤‡
                batch = self._move_batch_to_device(batch)
                labels = batch['label']  # å·²ç»åœ¨è®¾å¤‡ä¸Š

                # éªŒè¯æ—¶ä¹Ÿä½¿ç”¨åŒå¤´è¾“å‡ºå’Œå®Œæ•´æŸå¤±
                if self.use_amp:
                    with torch.cuda.amp.autocast():
                        softmax_logits, arcface_logits, features = self.model(
                            batch, mode='supervised'
                        )
                        loss, loss_dict = self.criterion(softmax_logits, arcface_logits, labels)
                else:
                    softmax_logits, arcface_logits, features = self.model(
                        batch, mode='supervised'
                    )
                    loss, loss_dict = self.criterion(softmax_logits, arcface_logits, labels)

                # ç»Ÿè®¡å‡†ç¡®ç‡ - ä½¿ç”¨softmax_logits
                predictions = torch.argmax(softmax_logits, dim=1)
                correct = (predictions == labels).sum().item()

                total_correct += correct
                total_samples += labels.size(0)
                total_loss += loss.item()

                # æ›´æ–°è¿›åº¦æ¡
                pbar.set_postfix({
                    'loss': loss.item(),
                    'acc': total_correct / total_samples
                })

        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        avg_loss = total_loss / len(self.val_loader)
        avg_acc = total_correct / total_samples

        return {
            'val_loss': avg_loss,
            'val_acc': avg_acc
        }

    def compute_loss(self, batch, labels=None):
        """
        è®¡ç®—æŸå¤±ï¼ˆç”¨äºåŸºç±»çš„é€šç”¨è®­ç»ƒæµç¨‹ï¼‰

        Args:
            batch: è¾“å…¥æ‰¹æ¬¡
            labels: æ ‡ç­¾ï¼ˆå¦‚æœNoneï¼Œä»batchä¸­è·å–ï¼‰

        Returns:
            loss: æŸå¤±å€¼
            loss_dict: æŸå¤±ç»„æˆå­—å…¸
        """
        if labels is None:
            labels = batch['label']

        # å‰å‘ä¼ æ’­
        if self.use_amp:
            with torch.cuda.amp.autocast():
                softmax_logits, arcface_logits, features = self.model(
                    batch, mode='supervised'
                )
                loss, loss_dict = self.criterion(softmax_logits, arcface_logits, labels)
        else:
            softmax_logits, arcface_logits, features = self.model(
                batch, mode='supervised'
            )
            loss, loss_dict = self.criterion(softmax_logits, arcface_logits, labels)

        return loss, loss_dict

    def setup_callbacks(
            self,
            early_stopping_config: Dict[str, Any],
            checkpoint_config: Dict[str, Any]
    ):
        """
        è®¾ç½®callbacks (è¦†ç›–çˆ¶ç±»æ–¹æ³•ä»¥é€‚é…ç›‘ç£å­¦ä¹ )

        å¯¹äºç›‘ç£å­¦ä¹ :
        - EarlyStopping ç›‘æ§ é…ç½®æŒ‡å®šçš„æŒ‡æ ‡ (é€šå¸¸æ˜¯'val_acc', mode='max')
        - ModelCheckpoint ç›‘æ§ é…ç½®æŒ‡å®šçš„æŒ‡æ ‡ (é€šå¸¸æ˜¯'val_acc', mode='max')

        Args:
            early_stopping_config: æ—©åœé…ç½®
            checkpoint_config: checkpointé…ç½®
        """
        print("\né…ç½®Callbacks:")

        # æ—©åœé…ç½®
        if early_stopping_config.get('enable', True):
            monitor = early_stopping_config.get('monitor', 'val_acc')
            mode = early_stopping_config.get('mode', 'max')

            early_stopping = EarlyStopping(
                patience=early_stopping_config.get('patience', 15),
                monitor=monitor,
                mode=mode,
                restore_best_weights=early_stopping_config.get('restore_best_weights', True)
            )
            self.add_callback(early_stopping)
            print(f"  âœ… EarlyStopping:")
            print(f"     - monitor: {monitor}")
            print(f"     - mode: {mode}")
            print(f"     - patience: {early_stopping.patience}")

        # Checkpointé…ç½®
        if checkpoint_config.get('save_best', True):
            monitor = checkpoint_config.get('monitor_metric', 'val_acc')
            mode = checkpoint_config.get('monitor_mode', 'max')

            model_checkpoint = ModelCheckpoint(
                save_dir=self.checkpoint_manager.checkpoint_dir,
                monitor=monitor,
                mode=mode,
                save_frequency=checkpoint_config.get('save_frequency', 5),
                keep_last_n=checkpoint_config.get('keep_last_n', 3)
            )
            self.add_callback(model_checkpoint)
            print(f"  âœ… ModelCheckpoint:")
            print(f"     - monitor: {monitor}")
            print(f"     - mode: {mode}")
            print(f"     - save_frequency: {checkpoint_config.get('save_frequency', 5)}")
            print(f"     - keep_last_n: {checkpoint_config.get('keep_last_n', 3)}")

    def train(
            self,
            epochs: int,
            log_interval: int = 10,
            save_config: Optional[Dict] = None
    ):
        """
        å®Œæ•´è®­ç»ƒæµç¨‹ (å¸¦è¿›åº¦æ¡å’Œå®Œå–„çš„callbackæœºåˆ¶)

        Args:
            epochs: è®­ç»ƒè½®æ•°
            log_interval: æ—¥å¿—æ‰“å°é—´éš”
            save_config: ä¿å­˜é…ç½®
        """
        print("=" * 80)
        print(f"å¼€å§‹æœ‰ç›‘ç£è®­ç»ƒ: {epochs} epochs")
        print(f"è®¾å¤‡: {self.device}")
        print(f"è®­ç»ƒæ ·æœ¬æ•°: {len(self.train_loader.dataset)}")
        print(f"éªŒè¯æ ·æœ¬æ•°: {len(self.val_loader.dataset)}")
        print(f"Batch size: {self.train_loader.batch_size}")
        print("=" * 80)

        # ä¿å­˜é…ç½®
        if save_config:
            self._save_config(save_config)

        # è®­ç»ƒå¾ªç¯
        for epoch in range(epochs):
            self.current_epoch = epoch
            epoch_start_time = time.time()

            # ğŸ”§ å¦‚æœä½¿ç”¨æ¸è¿›å¼æŸå¤±ï¼Œæ›´æ–°æŸå¤±æƒé‡
            if isinstance(self.criterion, ProgressiveCombinedLoss):
                self.criterion.update_weights(epoch, epochs)

            # è®­ç»ƒä¸€ä¸ªepoch
            train_metrics = self.train_epoch(epoch=epoch, log_interval=log_interval)

            # éªŒè¯ä¸€ä¸ªepoch
            val_metrics = self.validate_epoch(epoch=epoch)

            # æ›´æ–°å­¦ä¹ ç‡
            self._update_lr(val_metrics)

            # è®°å½•å­¦ä¹ ç‡
            lr = self.optimizer.param_groups[0]['lr']

            # è®°å½•æŒ‡æ ‡
            epoch_metrics = {
                **train_metrics,
                **val_metrics,
                'learning_rate': lr
            }
            self.metrics_tracker.update(epoch_metrics)

            # å›è°ƒ
            callback_metrics = {
                'epoch': epoch,
                'train_loss': train_metrics.get('train_loss', 0),
                'val_loss': val_metrics.get('val_loss', 0),
                'val_acc': val_metrics.get('val_acc', 0)
            }
            self.callbacks.on_epoch_end(epoch, callback_metrics, self.model, self.optimizer)

            # æ‰“å°epochæ€»ç»“
            epoch_time = time.time() - epoch_start_time
            self._print_epoch_summary(epoch, epochs, train_metrics, val_metrics, epoch_time)

            # æ£€æŸ¥æ—©åœ
            if self.callbacks.should_stop():
                print(f"\n{'=' * 80}")
                print(f"æ—©åœè§¦å‘ï¼Œåœ¨ç¬¬ {epoch + 1} è½®åœæ­¢è®­ç»ƒ")
                print(f"{'=' * 80}")
                break

        # è®­ç»ƒç»“æŸ
        print("\n" + "=" * 80)
        print("æœ‰ç›‘ç£è®­ç»ƒå®Œæˆ!")
        print("=" * 80)

        # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
        self._plot_curves()

        # åŠ è½½æœ€ä½³æ¨¡å‹
        self._load_best_model()

    def _print_epoch_summary(
            self,
            epoch: int,
            total_epochs: int,
            train_metrics: Dict[str, float],
            val_metrics: Dict[str, float],
            epoch_time: float
    ):
        """æ‰“å°epochæ€»ç»“ä¿¡æ¯"""
        lr = self.optimizer.param_groups[0]['lr']

        print(f"\n{'=' * 80}")
        print(f"Epoch [{epoch + 1:3d}/{total_epochs}] æ€»ç»“:")
        print(f"  - è®­ç»ƒæŸå¤±: {train_metrics['train_loss']:.4f}")
        print(f"  - è®­ç»ƒå‡†ç¡®ç‡: {train_metrics['train_acc']:.4f}")
        print(f"  - éªŒè¯æŸå¤±: {val_metrics['val_loss']:.4f}")
        print(f"  - éªŒè¯å‡†ç¡®ç‡: {val_metrics['val_acc']:.4f}")
        print(f"  - å­¦ä¹ ç‡: {lr:.6f}")
        print(f"  - ç”¨æ—¶: {epoch_time:.2f}s")
        print(f"{'=' * 80}")

    def _plot_curves(self):
        """
        ç»˜åˆ¶è®­ç»ƒæ›²çº¿

        å¯¹äºç›‘ç£å­¦ä¹ ï¼Œä¸»è¦ç»˜åˆ¶:
        - æŸå¤±æ›²çº¿ (train_loss vs val_loss)
        - å‡†ç¡®ç‡æ›²çº¿ (train_acc vs val_acc)
        - å­¦ä¹ ç‡æ›²çº¿
        """
        print("\nç»˜åˆ¶è®­ç»ƒæ›²çº¿...")

        # ç¡®ä¿å¯è§†åŒ–ç›®å½•å­˜åœ¨
        vis_dir = Path(self.experiment_dir) / 'visualizations'
        vis_dir.mkdir(parents=True, exist_ok=True)

        # è·å–è®­ç»ƒå†å²
        history = self.metrics_tracker.get_history()

        # åˆ›å»ºå¯è§†åŒ–å™¨
        visualizer = TrainingVisualizer(save_dir=str(vis_dir))

        # ç»˜åˆ¶æŸå¤±æ›²çº¿
        if 'train_loss' in history and 'val_loss' in history:
            visualizer.plot_loss_curves(
                train_loss=history['train_loss'],
                val_loss=history['val_loss'],
                title='Training and Validation Loss',
                save_name='loss_curves.png',
                show=False
            )
            print(f"  âœ“ æŸå¤±æ›²çº¿å·²ä¿å­˜: {vis_dir / 'loss_curves.png'}")

        # ç»˜åˆ¶å‡†ç¡®ç‡æ›²çº¿
        if 'train_acc' in history and 'val_acc' in history:
            visualizer.plot_accuracy_curves(
                train_acc=history['train_acc'],
                val_acc=history['val_acc'],
                title='Training and Validation Accuracy',
                save_name='accuracy_curves.png',
                show=False
            )
            print(f"  âœ“ å‡†ç¡®ç‡æ›²çº¿å·²ä¿å­˜: {vis_dir / 'accuracy_curves.png'}")

        # ç»˜åˆ¶å­¦ä¹ ç‡æ›²çº¿
        if 'learning_rate' in history and len(history['learning_rate']) > 0:
            visualizer.plot_learning_rate(
                learning_rates=history['learning_rate'],
                title='Learning Rate Schedule',
                save_name='learning_rate.png',
                show=False
            )
            print(f"  âœ“ å­¦ä¹ ç‡æ›²çº¿å·²ä¿å­˜: {vis_dir / 'learning_rate.png'}")

        print("\n  è¯„ä¼°éªŒè¯é›†å¹¶ç”Ÿæˆå¯è§†åŒ–...")
        self._plot_evaluation_visualizations(vis_dir)
        print("âœ“ è®­ç»ƒæ›²çº¿ç»˜åˆ¶å®Œæˆ")

    def _plot_evaluation_visualizations(self, vis_dir: Path):
        """åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°å¹¶ç”Ÿæˆæ··æ·†çŸ©é˜µå’Œt-SNEå¯è§†åŒ–"""

        # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼ä½†ä¿æŒåŒå¤´è¾“å‡º
        self.model.train()
        for module in self.model.modules():
            if isinstance(module, (nn.Dropout, nn.BatchNorm1d, nn.BatchNorm2d)):
                module.eval()

        all_labels = []
        all_preds = []
        all_features = []

        print("    æ”¶é›†éªŒè¯é›†é¢„æµ‹å’Œç‰¹å¾...")
        with torch.no_grad():
            for batch in tqdm(self.val_loader, desc="    æå–ç‰¹å¾", leave=False, ncols=80):
                batch = self._move_batch_to_device(batch)
                labels = batch['label']

                # å‰å‘ä¼ æ’­è·å–ç‰¹å¾
                if self.use_amp:
                    with torch.cuda.amp.autocast():
                        softmax_logits, arcface_logits, features = self.model(
                            batch, mode='supervised'
                        )
                else:
                    softmax_logits, arcface_logits, features = self.model(
                        batch, mode='supervised'
                    )

                # æ”¶é›†é¢„æµ‹å’Œç‰¹å¾
                predictions = torch.argmax(softmax_logits, dim=1)
                all_labels.append(labels.cpu().numpy())
                all_preds.append(predictions.cpu().numpy())
                all_features.append(features.cpu().numpy())

        # åˆå¹¶æ‰€æœ‰batch
        all_labels = np.concatenate(all_labels)
        all_preds = np.concatenate(all_preds)
        all_features = np.concatenate(all_features)

        # 1. ç»˜åˆ¶æ··æ·†çŸ©é˜µ
        print("    ç»˜åˆ¶æ··æ·†çŸ©é˜µ...")
        cm = confusion_matrix(all_labels, all_preds)

        plt.figure(figsize=(10, 8))
        sns.heatmap(
            cm,
            annot=True,
            fmt='d',
            cmap='Blues',
            xticklabels=range(cm.shape[0]),
            yticklabels=range(cm.shape[1]),
            cbar_kws={'label': 'Count'}
        )
        plt.title('Confusion Matrix', fontsize=14, fontweight='bold', pad=15)
        plt.xlabel('Predicted Label', fontsize=12)
        plt.ylabel('True Label', fontsize=12)
        plt.tight_layout()

        cm_path = vis_dir / 'confusion_matrix.png'
        plt.savefig(cm_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"    âœ“ æ··æ·†çŸ©é˜µå·²ä¿å­˜: {cm_path}")

        # 2. ç»˜åˆ¶å½’ä¸€åŒ–æ··æ·†çŸ©é˜µ
        print("    ç»˜åˆ¶å½’ä¸€åŒ–æ··æ·†çŸ©é˜µ...")
        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

        plt.figure(figsize=(10, 8))
        sns.heatmap(
            cm_normalized,
            annot=True,
            fmt='.2f',
            cmap='Blues',
            xticklabels=range(cm.shape[0]),
            yticklabels=range(cm.shape[1]),
            cbar_kws={'label': 'Proportion'},
            vmin=0,
            vmax=1
        )
        plt.title('Normalized Confusion Matrix', fontsize=14, fontweight='bold', pad=15)
        plt.xlabel('Predicted Label', fontsize=12)
        plt.ylabel('True Label', fontsize=12)
        plt.tight_layout()

        cm_norm_path = vis_dir / 'confusion_matrix_normalized.png'
        plt.savefig(cm_norm_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"    âœ“ å½’ä¸€åŒ–æ··æ·†çŸ©é˜µå·²ä¿å­˜: {cm_norm_path}")

        # 3. ç»˜åˆ¶t-SNEå¯è§†åŒ–
        print("    ç»˜åˆ¶t-SNEå¯è§†åŒ–...")

        # é™é‡‡æ ·ä»¥åŠ é€Ÿï¼ˆå¦‚æœæ ·æœ¬å¤ªå¤šï¼‰
        max_samples = 2000
        if len(all_features) > max_samples:
            indices = np.random.choice(len(all_features), max_samples, replace=False)
            features_subset = all_features[indices]
            labels_subset = all_labels[indices]
        else:
            features_subset = all_features
            labels_subset = all_labels

        # æ‰§è¡Œt-SNE
        tsne = TSNE(n_components=2, random_state=42, perplexity=30)
        features_2d = tsne.fit_transform(features_subset)

        # ç»˜åˆ¶t-SNEå›¾
        plt.figure(figsize=(12, 10))
        num_classes = len(np.unique(labels_subset))
        colors = plt.cm.tab10(np.linspace(0, 1, num_classes))

        for i in range(num_classes):
            mask = labels_subset == i
            plt.scatter(
                features_2d[mask, 0],
                features_2d[mask, 1],
                c=[colors[i]],
                label=f'Class {i}',
                alpha=0.6,
                s=50,
                edgecolors='black',
                linewidths=0.5
            )

        plt.xlabel('t-SNE Component 1', fontsize=12)
        plt.ylabel('t-SNE Component 2', fontsize=12)
        plt.title('t-SNE Visualization of Features', fontsize=14, fontweight='bold', pad=15)
        plt.legend(fontsize=10, loc='best', framealpha=0.9)
        plt.grid(True, alpha=0.3, linestyle='--')
        plt.tight_layout()

        tsne_path = vis_dir / 'tsne_visualization.png'
        plt.savefig(tsne_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"    âœ“ t-SNEå¯è§†åŒ–å·²ä¿å­˜: {tsne_path}")

        # 4. æ‰“å°åˆ†ç±»æŠ¥å‘Š
        print("\n    åˆ†ç±»æŠ¥å‘Š:")
        print(classification_report(
            all_labels,
            all_preds,
            target_names=[f'Class {i}' for i in range(num_classes)],
            digits=4
        ))

# ============================================================================
# é¢„è®­ç»ƒæƒé‡åŠ è½½å·¥å…·å‡½æ•°
# ============================================================================

def load_pretrained_weights(
        model: nn.Module,
        pretrained_path: str,
        device: str = 'cuda',
        freeze_backbone: bool = False,
        freeze_ratio: float = 0.5,
        strict: bool = False
) -> nn.Module:
    """
    åŠ è½½é¢„è®­ç»ƒæƒé‡ (ä»…åŠ è½½backboneï¼Œä¸åŠ è½½projection_headå’Œclassifier)

    Args:
        model: ç›®æ ‡æ¨¡å‹
        pretrained_path: é¢„è®­ç»ƒæƒé‡è·¯å¾„
        device: è®¾å¤‡
        freeze_backbone: æ˜¯å¦å†»ç»“backbone
        freeze_ratio: å†»ç»“æ¯”ä¾‹ (0.0-1.0)
        strict: æ˜¯å¦ä¸¥æ ¼åŒ¹é…æƒé‡

    Returns:
        model: åŠ è½½æƒé‡åçš„æ¨¡å‹
    """
    print(f"\n{'=' * 80}")
    print(f"åŠ è½½é¢„è®­ç»ƒæƒé‡: {pretrained_path}")
    print(f"{'=' * 80}")

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(pretrained_path).exists():
        raise FileNotFoundError(f"é¢„è®­ç»ƒæƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {pretrained_path}")

    # åŠ è½½é¢„è®­ç»ƒæƒé‡
    checkpoint = torch.load(pretrained_path, map_location=device)

    # æå–æ¨¡å‹æƒé‡
    if 'model_state_dict' in checkpoint:
        pretrained_dict = checkpoint['model_state_dict']
        print(f"âœ“ ä»checkpointä¸­æå–é¢„è®­ç»ƒæƒé‡")
        if 'epoch' in checkpoint:
            print(f"  - é¢„è®­ç»ƒepoch: {checkpoint['epoch']}")
        if 'best_val_loss' in checkpoint:
            print(f"  - æœ€ä½³éªŒè¯æŸå¤±: {checkpoint['best_val_loss']:.4f}")
    else:
        pretrained_dict = checkpoint
        print(f"âœ“ ç›´æ¥åŠ è½½é¢„è®­ç»ƒæƒé‡")

    # è·å–æ¨¡å‹å½“å‰çš„state_dict
    model_dict = model.state_dict()

    # è¿‡æ»¤å‡ºåŒ¹é…çš„æƒé‡ï¼ˆæ’é™¤projection_headå’Œclassifierï¼‰
    matched_dict = {}
    unmatched_keys = []

    for k, v in pretrained_dict.items():
        # æ£€æŸ¥keyæ˜¯å¦åœ¨æ¨¡å‹ä¸­å­˜åœ¨
        if k in model_dict:
            # æ£€æŸ¥shapeæ˜¯å¦åŒ¹é…
            if model_dict[k].shape == v.shape:
                matched_dict[k] = v
            else:
                unmatched_keys.append(f"{k} (shape mismatch: {model_dict[k].shape} vs {v.shape})")
        else:
            unmatched_keys.append(f"{k} (not in model)")

    # æ›´æ–°æ¨¡å‹æƒé‡
    model_dict.update(matched_dict)
    model.load_state_dict(model_dict, strict=False)

    print(f"\nâœ“ é¢„è®­ç»ƒæƒé‡åŠ è½½å®Œæˆ")
    print(f"  - åŒ¹é…å‚æ•°æ•°é‡: {len(matched_dict)}")
    print(f"  - æœªåŒ¹é…å‚æ•°æ•°é‡: {len(unmatched_keys)}")

    if unmatched_keys:
        print(f"\næœªåŒ¹é…çš„å‚æ•°:")
        for key in unmatched_keys[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            print(f"  - {key}")
        if len(unmatched_keys) > 5:
            print(f"  ... è¿˜æœ‰ {len(unmatched_keys) - 5} ä¸ªæœªåŒ¹é…å‚æ•°")

    # å†»ç»“backboneï¼ˆå¦‚æœéœ€è¦ï¼‰
    if freeze_backbone:
        print(f"\nå†»ç»“backboneå‚æ•° (freeze_ratio={freeze_ratio}):")

        # è·å–æ‰€æœ‰éœ€è¦å†»ç»“çš„å±‚
        backbone_params = [
            name for name, param in model.named_parameters()
            if 'classifier' not in name and 'projection_head' not in name
        ]

        num_to_freeze = int(len(backbone_params) * freeze_ratio)
        frozen_params = backbone_params[:num_to_freeze]

        for name, param in model.named_parameters():
            if name in frozen_params:
                param.requires_grad = False

        print(f"  - æ€»backboneå‚æ•°: {len(backbone_params)}")
        print(f"  - å†»ç»“å‚æ•°æ•°é‡: {num_to_freeze}")
        print(f"  - å¯è®­ç»ƒå‚æ•°æ•°é‡: {len(backbone_params) - num_to_freeze}")

    print(f"{'=' * 80}\n")

    return model

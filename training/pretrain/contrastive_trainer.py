"""
å¯¹æ¯”å­¦ä¹ è®­ç»ƒå™¨
ç”¨äºé¢„è®­ç»ƒé˜¶æ®µçš„è‡ªç›‘ç£å­¦ä¹ 
"""
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torch.optim.lr_scheduler import ReduceLROnPlateau
from typing import Dict, Any, Tuple
from tqdm import tqdm
import os
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from training.trainer_base import TrainerBase
from losses import NTXentLoss, SupConLoss
from training.scheduler_factory import WarmupScheduler


class ContrastiveTrainer(TrainerBase):
    """å¯¹æ¯”å­¦ä¹ è®­ç»ƒå™¨"""

    def __init__(
        self,
        model: nn.Module,
        train_loader: DataLoader,
        val_loader: DataLoader,
        optimizer: torch.optim.Optimizer,
        scheduler: Any,
        loss_type: str = 'ntxent',
        temperature: float = 0.07,
        device: str = 'cuda',
        experiment_dir: str = 'experiments/runs',
        use_amp: bool = False,
        gradient_clip_max_norm: float = 1.0
    ):
        """
        Args:
            model: æ¨¡å‹
            train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨(å¯¹æ¯”å­¦ä¹ æ•°æ®é›†)
            val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
            optimizer: ä¼˜åŒ–å™¨
            scheduler: å­¦ä¹ ç‡è°ƒåº¦å™¨
            loss_type: æŸå¤±ç±»å‹ 'ntxent' | 'supcon'
            temperature: æ¸©åº¦å‚æ•°
            device: è®­ç»ƒè®¾å¤‡
            experiment_dir: å®éªŒä¿å­˜ç›®å½•
            use_amp: æ˜¯å¦ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
            gradient_clip_max_norm: æ¢¯åº¦è£å‰ªçš„æœ€å¤§èŒƒæ•°
        """
        super().__init__(
            model, train_loader, val_loader, optimizer, scheduler,
            device, experiment_dir, use_amp
        )

        self.loss_type = loss_type
        self.temperature = temperature
        self.gradient_clip_max_norm = gradient_clip_max_norm

        # åˆ›å»ºå¯¹æ¯”å­¦ä¹ æŸå¤±
        if loss_type == 'ntxent':
            self.criterion = NTXentLoss(temperature=temperature)
        elif loss_type == 'supcon':
            self.criterion = SupConLoss(temperature=temperature)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æŸå¤±ç±»å‹: {loss_type}")

        # æ£€æŸ¥scheduleræ˜¯å¦éœ€è¦metric
        self.scheduler_needs_metric = self._check_scheduler_needs_metric()

        print(f"ContrastiveTraineråˆå§‹åŒ–å®Œæˆ")
        print(f"  - æŸå¤±ç±»å‹: {loss_type}")
        print(f"  - æ¸©åº¦å‚æ•°: {temperature}")
        print(f"  - æ¢¯åº¦è£å‰ª: {gradient_clip_max_norm}")

    def setup_callbacks(self, early_stopping_config: Dict, checkpoint_config: Dict):
        """
        ğŸ”§ ä¿®å¤: é‡å†™callbacksè®¾ç½®,ç¡®ä¿é¢„è®­ç»ƒç›‘æ§æ­£ç¡®çš„æŒ‡æ ‡

        å¯¹äºé¢„è®­ç»ƒ:
        - EarlyStopping ç›‘æ§ 'val_loss' (éªŒè¯é›†å¯¹æ¯”æŸå¤±)
        - ModelCheckpoint ç›‘æ§ 'val_loss' (è€Œé val_acc,å› ä¸ºé¢„è®­ç»ƒæ²¡æœ‰å‡†ç¡®ç‡)
        """
        from training.callbacks import EarlyStopping, ModelCheckpoint

        # æ—©åœ
        if early_stopping_config.get('enable', True):
            # ğŸ”§ é¢„è®­ç»ƒé˜¶æ®µåº”è¯¥ç›‘æ§ val_loss
            monitor = early_stopping_config.get('monitor', 'val_loss')
            if monitor == 'loss':
                monitor = 'val_loss'  # ç»Ÿä¸€ä½¿ç”¨éªŒè¯é›†æŒ‡æ ‡

            early_stopping = EarlyStopping(
                patience=early_stopping_config.get('patience', 10),
                monitor=monitor,
                mode=early_stopping_config.get('mode', 'min'),
                restore_best_weights=early_stopping_config.get('restore_best_weights', True)
            )
            self.add_callback(early_stopping)
            print(f"  âœ… EarlyStopping: monitor={monitor}, mode=min, patience={early_stopping_config.get('patience', 10)}")

        # æ¨¡å‹ä¿å­˜
        if checkpoint_config.get('save_best', True):
            # ğŸ”§ é¢„è®­ç»ƒé˜¶æ®µå¼ºåˆ¶ç›‘æ§ val_loss (å¿½ç•¥é…ç½®æ–‡ä»¶ä¸­çš„ val_acc)
            model_checkpoint = ModelCheckpoint(
                save_dir=self.checkpoint_manager.checkpoint_dir,
                monitor='val_loss',  # ğŸ”§ é¢„è®­ç»ƒå›ºå®šç›‘æ§ val_loss
                mode='min',  # ğŸ”§ é¢„è®­ç»ƒå›ºå®šä¸º min æ¨¡å¼
                save_frequency=checkpoint_config.get('save_frequency', 5),
                keep_last_n=checkpoint_config.get('keep_last_n', 3)
            )
            self.add_callback(model_checkpoint)
            print(f"  âœ… ModelCheckpoint: monitor=val_loss, mode=min")

    def _check_scheduler_needs_metric(self) -> bool:
        """æ£€æŸ¥è°ƒåº¦å™¨æ˜¯å¦éœ€è¦metric(å¦‚ReduceLROnPlateau)"""
        return isinstance(self.scheduler, ReduceLROnPlateau)

    def train_epoch(self) -> Dict[str, float]:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0
        num_batches = 0

        pbar = tqdm(self.train_loader, desc=f'Train Epoch {self.current_epoch}')

        for batch in pbar:
            # è®¡ç®—æŸå¤±
            loss, _ = self.compute_loss(batch)

            # åå‘ä¼ æ’­
            if self.use_amp:
                self.scaler.scale(loss).backward()
                if self.gradient_clip_max_norm > 0:
                    self.scaler.unscale_(self.optimizer)
                    torch.nn.utils.clip_grad_norm_(
                        self.model.parameters(),
                        self.gradient_clip_max_norm
                    )
                self.scaler.step(self.optimizer)
                self.scaler.update()
            else:
                loss.backward()
                if self.gradient_clip_max_norm > 0:
                    torch.nn.utils.clip_grad_norm_(
                        self.model.parameters(),
                        self.gradient_clip_max_norm
                    )
                self.optimizer.step()

            self.optimizer.zero_grad()

            # ç´¯è®¡ç»Ÿè®¡
            total_loss += loss.item()
            num_batches += 1
            self.global_step += 1

            # æ›´æ–°è¿›åº¦æ¡
            pbar.set_postfix({'loss': loss.item()})

        avg_loss = total_loss / num_batches

        return {
            'loss': avg_loss,
            'train_loss': avg_loss
        }

    def validate_epoch(self) -> Dict[str, float]:
        """éªŒè¯ä¸€ä¸ªepoch"""
        self.model.eval()
        total_loss = 0
        num_batches = 0

        with torch.no_grad():
            for batch in tqdm(self.val_loader, desc='Validation'):
                loss, _ = self.compute_loss(batch)
                total_loss += loss.item()
                num_batches += 1

        avg_loss = total_loss / num_batches

        return {
            'loss': avg_loss,
            'val_loss': avg_loss
        }

    def compute_loss(self, batch: Dict[str, torch.Tensor]) -> Tuple[torch.Tensor, Dict[str, float]]:
        """
        è®¡ç®—å¯¹æ¯”å­¦ä¹ æŸå¤±

        Args:
            batch: æ•°æ®æ‰¹æ¬¡,åŒ…å«ä¸¤ä¸ªå¢å¼ºè§†å›¾
                   æ ¼å¼: {'view1': {...}, 'view2': {...}, 'label': ...}

        Returns:
            loss: æŸå¤±å€¼
            metrics: æŒ‡æ ‡å­—å…¸
        """
        # ğŸ”§ ä¿®å¤: ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡
        view1 = {
            'temporal': batch['view1']['temporal'].to(self.device),
            'frequency': batch['view1']['frequency'].to(self.device),
            'timefreq': batch['view1']['timefreq'].to(self.device)
        }

        view2 = {
            'temporal': batch['view2']['temporal'].to(self.device),
            'frequency': batch['view2']['frequency'].to(self.device),
            'timefreq': batch['view2']['timefreq'].to(self.device)
        }

        # ğŸ”§ ä¿®å¤: æ„å»ºæ¨¡å‹éœ€è¦çš„batchæ ¼å¼
        # æ¨¡å‹çš„forwardæœŸæœ›: batch = {'view1': {...}, 'view2': {...}}
        model_batch = {'view1': view1, 'view2': view2}

        # å¦‚æœä½¿ç”¨SupCon,è¿˜éœ€è¦ä¼ é€’æ ‡ç­¾
        if 'label' in batch:
            model_batch['label'] = batch['label'].to(self.device)

        # å‰å‘ä¼ æ’­ (å¯¹æ¯”å­¦ä¹ æ¨¡å¼)
        if self.use_amp:
            with torch.amp.autocast(device_type='cuda' if 'cuda' in self.device else 'cpu'):
                z1, z2 = self.model(model_batch, mode='contrastive')
                loss = self.criterion(z1, z2)
        else:
            z1, z2 = self.model(model_batch, mode='contrastive')
            loss = self.criterion(z1, z2)

        metrics = {
            'loss': loss.item()
        }

        return loss, metrics

    def train(self, epochs: int, log_interval: int = 10, save_config: Dict = None):
        """
        è®­ç»ƒä¸»å¾ªç¯

        Args:
            epochs: è®­ç»ƒè½®æ•°
            log_interval: æ—¥å¿—æ‰“å°é—´éš”
            save_config: ä¿å­˜çš„é…ç½®ä¿¡æ¯
        """
        print(f"\nå¼€å§‹è®­ç»ƒ {epochs} ä¸ªepochs...")
        print(f"  - è®­ç»ƒé›†: {len(self.train_loader.dataset)} æ ·æœ¬")
        print(f"  - éªŒè¯é›†: {len(self.val_loader.dataset)} æ ·æœ¬")
        print(f"  - Batch size: {self.train_loader.batch_size}")

        # ä¿å­˜é…ç½®
        if save_config is not None:
            self._save_config(save_config)

        history = {
            'train_loss': [],
            'val_loss': []
        }

        for epoch in range(epochs):
            self.current_epoch = epoch

            # è®­ç»ƒ
            train_metrics = self.train_epoch()

            # éªŒè¯
            val_metrics = self.validate_epoch()

            # åˆå¹¶æŒ‡æ ‡
            epoch_metrics = {**train_metrics, **val_metrics}

            # è®°å½•å†å²
            history['train_loss'].append(train_metrics['loss'])
            history['val_loss'].append(val_metrics['loss'])

            # æ‰“å°æ—¥å¿—
            print(f"\nEpoch {epoch+1}/{epochs}")
            print(f"  Train Loss: {train_metrics['loss']:.4f}")
            print(f"  Val Loss: {val_metrics['loss']:.4f}")

            # è°ƒç”¨callbacks
            self.callbacks.on_epoch_end(epoch, epoch_metrics, self.model, self.optimizer)

            # æ›´æ–°å­¦ä¹ ç‡
            if self.scheduler is not None:
                if self.scheduler_needs_metric:
                    self.scheduler.step(val_metrics['loss'])
                else:
                    self.scheduler.step()

                current_lr = self.optimizer.param_groups[0]['lr']
                print(f"  Learning Rate: {current_lr:.6f}")

            # æ£€æŸ¥æ—©åœ
            if self.callbacks.should_stop():
                print(f"\næ—©åœè§¦å‘,åœæ­¢è®­ç»ƒ")
                break

        # è®­ç»ƒç»“æŸååŠ è½½æœ€ä½³æ¨¡å‹
        self._load_best_model()

        # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
        self._plot_curves(history)

        print("\nè®­ç»ƒå®Œæˆ!")

    def save_pretrained_weights(self, save_path: str):
        """
        ğŸ”§ æ–°å¢æ–¹æ³•: ä¿å­˜é¢„è®­ç»ƒæƒé‡

        åªä¿å­˜æ¨¡å‹çš„state_dict,ç”¨äºåç»­å¾®è°ƒé˜¶æ®µåŠ è½½
        æ³¨æ„: ä¼šæ’é™¤projection_headçš„æƒé‡(å› ä¸ºå¾®è°ƒä¸éœ€è¦)

        Args:
            save_path: ä¿å­˜è·¯å¾„
        """
        print(f"\nä¿å­˜é¢„è®­ç»ƒæƒé‡åˆ°: {save_path}")

        # è·å–å®Œæ•´çš„state_dict
        full_state_dict = self.model.state_dict()

        # ğŸ”§ åªä¿ç•™backboneæƒé‡,æ’é™¤projection_headå’Œclassifier
        pretrained_dict = {}
        excluded_keys = []

        for k, v in full_state_dict.items():
            # æ’é™¤æŠ•å½±å¤´å’Œåˆ†ç±»å™¨
            if 'projection_head' in k or 'classifier' in k:
                excluded_keys.append(k)
                continue
            pretrained_dict[k] = v

        # ä¿å­˜
        torch.save({
            'model_state_dict': pretrained_dict,
            'epoch': self.current_epoch,
            'temperature': self.temperature,
            'loss_type': self.loss_type
        }, save_path)

        print(f"âœ“ é¢„è®­ç»ƒæƒé‡ä¿å­˜æˆåŠŸ")
        print(f"  - ä¿å­˜å‚æ•°: {len(pretrained_dict)} ä¸ª")
        print(f"  - æ’é™¤å‚æ•°: {len(excluded_keys)} ä¸ª")
        if excluded_keys:
            print(f"  - æ’é™¤çš„å±‚: {', '.join(set([k.split('.')[0] for k in excluded_keys]))}")


if __name__ == '__main__':
    """æµ‹è¯•ä»£ç """
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

    from models import create_model
    from datasets import ContrastiveDataset
    from torch.utils.data import DataLoader
    from training.optimizer_factory import create_optimizer_from_config
    from training.scheduler_factory import create_scheduler_from_config

    print("=" * 80)
    print("æµ‹è¯•ContrastiveTrainer (ä¿®å¤ç‰ˆ)")
    print("=" * 80)

    # åˆ›å»ºæ¨¡å‹
    model = create_model(config='small', enable_contrastive=True)
    print(f"âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸ")

    # åˆ›å»ºæ•°æ®é›†(ä½¿ç”¨å°‘é‡æ•°æ®æµ‹è¯•)
    print("\nåˆ›å»ºæ•°æ®é›†...")
    train_dataset = ContrastiveDataset(
        data_dir='raw_datasets/train',
        mode='train',
        fold=0,
        n_folds=5,
        use_labels=False,
        cache_data=False
    )

    train_loader = DataLoader(
        train_dataset,
        batch_size=4,
        shuffle=True,
        num_workers=0
    )

    val_loader = DataLoader(
        train_dataset,
        batch_size=4,
        shuffle=False,
        num_workers=0
    )

    print(f"âœ“ æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ")

    # åˆ›å»ºä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
    optimizer_config = {'type': 'adam', 'lr': 0.001}
    optimizer = create_optimizer_from_config(model, optimizer_config)

    scheduler_config = {'type': 'cosine', 'T_max': 10, 'eta_min': 1e-6}
    scheduler, needs_metric = create_scheduler_from_config(
        optimizer,
        scheduler_config,
        total_epochs=10
    )

    print(f"âœ“ ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨åˆ›å»ºæˆåŠŸ")
    print(f"  - Scheduleréœ€è¦metric: {needs_metric}")

    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = ContrastiveTrainer(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        optimizer=optimizer,
        scheduler=scheduler,
        loss_type='ntxent',
        temperature=0.07,
        device='cpu',
        experiment_dir='/tmp/test_contrastive_fixed',
        use_amp=False
    )

    print(f"âœ“ Traineråˆ›å»ºæˆåŠŸ")

    # è®¾ç½®callbacks
    print("\nè®¾ç½®callbacks...")
    trainer.setup_callbacks(
        early_stopping_config={'enable': True, 'patience': 3, 'monitor': 'val_loss'},
        checkpoint_config={'save_best': True, 'monitor_metric': 'val_acc'}  # è¿™é‡Œä¼šè¢«è¦†ç›–
    )

    # æµ‹è¯•ä¿å­˜é¢„è®­ç»ƒæƒé‡æ–¹æ³•
    print("\næµ‹è¯•save_pretrained_weightsæ–¹æ³•...")
    test_path = '/tmp/test_pretrained_weights.pth'
    trainer.save_pretrained_weights(test_path)

    # éªŒè¯ä¿å­˜çš„æ–‡ä»¶
    if os.path.exists(test_path):
        checkpoint = torch.load(test_path, map_location='cpu')
        print(f"\nâœ“ æƒé‡æ–‡ä»¶éªŒè¯æˆåŠŸ")
        print(f"  - Keys: {list(checkpoint.keys())}")
        print(f"  - Epoch: {checkpoint['epoch']}")
        print(f"  - å‚æ•°æ•°é‡: {len(checkpoint['model_state_dict'])}")

    print("\n" + "=" * 80)
    print("âœ“ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
    print("=" * 80)
